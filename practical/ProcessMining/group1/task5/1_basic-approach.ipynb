{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Basic Approach for Trace Clustering\n",
   "id": "51cf6a26414091cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Kmeans + One Hot Encoding\n",
    "\n",
    "Requirements:\n",
    "- ~~implement basic approach (one-hot-enconding + kmeans)~~\n",
    "- ~~hyperparameter experiments (grid-search)~~\n",
    "- ~~interpretation of clusters (one municipal? etc.)~~\n",
    "- ~~Notebook nicely presenting the clustering results for different hyperparameters~~"
   ],
   "id": "4aad88a8eac575b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from practical.ProcessMining.group1.shared import utils\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "BASE = utils.SAMPLES_PATH\n",
    "real_path = BASE / \"DomesticDeclarations_cleansed.csv\"\n",
    "event_log = utils.import_csv(BASE / \"DomesticDeclarations_cleansed.csv\")"
   ],
   "id": "7339cf495cdade52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# One-hot encode the event log\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "event_log_encoded = one_hot_encoder.fit_transform(event_log[[\"concept:name\"]])\n",
    "\n",
    "# Sample a subset of the data for faster computation\n",
    "sample_indices = np.random.choice(event_log_encoded.shape[0], size=1000, replace=False)\n",
    "event_log_sampled = event_log_encoded[sample_indices]\n",
    "\n",
    "# Apply KMeans clustering with hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_clusters': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'n_init': [10, 15, 20],\n",
    "    'max_iter': [300, 400, 500],\n",
    "}\n",
    "\n",
    "def evaluate_model(params, log):\n",
    "    k_means = KMeans(**params, random_state=42)\n",
    "    cluster_labels = k_means.fit_predict(log)\n",
    "    score = silhouette_score(log, cluster_labels)\n",
    "    return score, params\n",
    "        \n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_model)(params, event_log_sampled) for params in ParameterGrid(param_grid))\n",
    "\n",
    "best_score, best_params = max(results, key=lambda x: x[0])\n",
    "\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Params: {best_params}\")"
   ],
   "id": "82c2e918f406c228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Observations while implementation",
   "id": "899733e540fbec24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Improvement Steps:\n",
    "1. pure silhouette score calculation was too time consuming in combination with parameter tuning\n",
    "2. To improve, used sample logs of actual eventlog and parallelized execution\n",
    "\n",
    "Best score range: \n",
    "- 0.98 - 0.99\n",
    "\n",
    "Best params: \n",
    "- 'init': 'k-means++'\n",
    "- 'max_iter': 300\n",
    "- 'n_clusters': 10\n",
    "\n",
    "Mostly best params\n",
    "- 'n_init': 10}\n",
    "\n",
    "Explanation:\n",
    "- n_clusters: silhouette score calculates cluster affiliation, the more clusters are used, the better silhouette scores can be expected => overfitting problem, the more clusters, the better the score while cluster <= eventlog-unique-activities\n",
    "- max_iter: probably for sample set size, already after 300 iterations, no more changes\n",
    "- init: trivial, that k-means++ performance in average better than random"
   ],
   "id": "c54e1ba7dd0362ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Apply best parameters to original Event Log\n",
    "\n",
    "Next, using best parameters found for sample log to cluster the real log and add it as feature to each row of the eventlog"
   ],
   "id": "82bfc158970eac9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k_means = KMeans(**best_params, random_state=42)\n",
    "event_log['cluster'] = cluster_labels = k_means.fit_predict(event_log_encoded)\n",
    "# score = silhouette_score(event_log_encoded, cluster_labels)"
   ],
   "id": "ef8dd2fe99043c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split the event log into cluster sublogs\n",
    "cluster_sublogs = {}\n",
    "for cluster_label in event_log['cluster'].unique():\n",
    "    cluster_sublogs[cluster_label] = event_log[event_log['cluster'] == cluster_label]\n",
    "\n",
    "# Plotting the result\n",
    "cluster_sizes = [len(sublog) for sublog in cluster_sublogs.values()]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(cluster_sublogs)), cluster_sizes, color='skyblue')\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.title('Number of Events in Each Cluster')\n",
    "plt.xticks(range(len(cluster_sublogs)), labels=cluster_sublogs.keys())\n",
    "plt.show()"
   ],
   "id": "2fa6484fb066beda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally split the modified log by cluster label and save each sublog to a csv file, so that each one can be handled as standalone eventlog",
   "id": "f74112f8a2523a1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"base_approach\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "cluster_sublogs = {k: cluster_sublogs[k] for k in sorted(cluster_sublogs)}\n",
    "for cluster_label, df in cluster_sublogs.items():\n",
    "    file_path = os.path.join(base_dir, f\"cluster_{cluster_label}.csv\")\n",
    "    df.to_csv(file_path,sep=';',index=False)\n",
    "\n",
    "print(f\"Clusters exported to /base_approach\")"
   ],
   "id": "3eef9b87a0b7dfe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Visualization of Sublogs\n",
    "\n",
    "To visualize our result, we use pm4py alpha miner and own vizualizer implementation to visualize created sub models"
   ],
   "id": "176d7001432d2316"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from practical.ProcessMining.group1.shared.visualizer import Visualizer\n",
    "from practical.ProcessMining.group1.task4.tokenreplay import TokenReplay\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "for cluster_label, df in cluster_sublogs.items():   \n",
    "    event_log = log_converter.to_event_log.apply(df)\n",
    "\n",
    "    # Alpha Miner\n",
    "    alpha_net, alpha_initial_marking, alpha_final_marking = alpha_miner.apply(event_log)\n",
    "\n",
    "    alpha_token_replay = TokenReplay(event_log, alpha_net, alpha_initial_marking, alpha_final_marking, \"Alpha Miner\")\n",
    "\n",
    "    alpha_token_replay.run()  # alpha_token_replay.shuffle_activities()\n",
    "\n",
    "    vizard = Visualizer()\n",
    "    graph = vizard.build_petri_net(alpha_net, alpha_initial_marking, alpha_final_marking)\n",
    "    print(f'Cluster {cluster_label}: {df.shape[0]} events, {df[\"case:concept:name\"].unique().shape[0]} cases')\n",
    "    ## print(\"==== Cluster \", cluster_label, \"====\")\n",
    "\n",
    "    vizard.display(graph)"
   ],
   "id": "20cc57656969b1cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Observation\n",
    "Kmeans clustering (of this) eventlog results into\n",
    "- clusters containing exact one activity\n",
    "- an \"everything else\" cluster\n",
    "\n",
    "While naively reasonable, these result have a pretty low information level. It may be, that for outliers for example separating an activity into its own cluster is beneficial (even so, it has similar effects as base case handling with IMi, while less precise tuning/threshold capabilities), but after showing the exact same behavior for different n_cluster, it can be assumed that this clustering technique simply lacking information gain. \n",
    "\n",
    "Possible explanations / improvements:\n",
    "- silhouette score giving wrong incentives, lower score results could create clusters with more information gain\n",
    "- the event log could be too simple, for other if single/remaining results\n",
    "- one hot encoding is simply not suitable, due to ignored activity relationships"
   ],
   "id": "42133508ab9b0614"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To check, if the silhouette score is benefitting worse clustering or the observed behaviour is conditional to the used event log, we:\n",
    "- change the real event log\n",
    "- introduce a pre validation while hyperparameter tuning.\n",
    "\n",
    "When a kmeans cluster contains only single activity clusters and one remaining cluster, instead of calculating a silhouette score, we rate this with 0. If there should be a different clustering result, with worse silhouette score but not only containing (n_clusters - 1) * single activity clusters, this would get returned as best parameter. If that is not the case, best score would be 0, meaning all found trace clusters with kMeans and oneHotEncoding provide only trivial information gain.\n",
    "\n",
    "In addition we also include parameters that have been dropped in first parameter tuning assumed to be less impactful anyway"
   ],
   "id": "e999190861f274e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Alternative real log\n",
    "event_log = utils.import_xes(str(BASE / \"HospitalBilling.xes.gz\"))"
   ],
   "id": "a43d66699968841a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# One-hot encode the event log\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "event_log_encoded = one_hot_encoder.fit_transform(event_log[[\"concept:name\"]])\n",
    "\n",
    "# Sample a subset of the data for faster computation\n",
    "sample_indices = np.random.choice(event_log_encoded.shape[0], size=1000, replace=False)\n",
    "event_log_sampled = event_log_encoded[sample_indices]\n",
    "\n",
    "# Apply KMeans clustering with hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_clusters': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'n_init': [10, 15, 20],\n",
    "    'max_iter': [300, 400, 500],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "    'algorithm': ['lloyd', 'elkan'],\n",
    "    'random_state': [None, 42],\n",
    "    'copy_x': [True, False],\n",
    "}\n",
    "\n",
    "# Introduced pre validation\n",
    "def is_clustered_trivial(cluster_labels):\n",
    "    # Count activities in each cluster\n",
    "    unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    cluster_activity_counts = dict(zip(unique, counts))\n",
    "    \n",
    "    # Check for trivial clustering: all but one cluster have exactly one activity\n",
    "    trivial_clusters = sum(1 for count in cluster_activity_counts.values() if count == 1)\n",
    "    return trivial_clusters >= len(cluster_activity_counts) - 1\n",
    "    \n",
    "\n",
    "def evaluate_model(params, log):\n",
    "    k_means = KMeans(**params)\n",
    "    cluster_labels = k_means.fit_predict(log)\n",
    "    if is_clustered_trivial:\n",
    "        return 0, params\n",
    "    score = silhouette_score(log, cluster_labels)\n",
    "    return score, params\n",
    "        \n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_model)(params, event_log_sampled) for params in ParameterGrid(param_grid))\n",
    "\n",
    "best_score, best_params = max(results, key=lambda x: x[0])\n",
    "\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Params: {best_params}\")"
   ],
   "id": "5adf328fe41ced23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By these best score of 0, we can assume, that kmeans with one hot encoding is only producing trivial results with no real information gain. To make trace clustering useful during process mining, we need to apply more advanced techniques than hot encoding.",
   "id": "ac291b52f2af1545"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a1d1b807cc30c22c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
